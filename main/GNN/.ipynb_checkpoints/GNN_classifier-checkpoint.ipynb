{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e91891c-d42a-4811-9bd8-7d648b6057ef",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <span style=\"font-size: 24px; color: #003366; font-weight: 500;\">Predicting Molecule Binding using Graph Neural Network</span>\n",
    "    <img src=\"../logo.svg\" style=\"height: 50px; width: auto; margin-left: auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1fc6e-58e9-4b3c-821f-6b49dc64987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import rdkit\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import DataStructs, AllChem, Descriptors\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.nn import Linear, Dropout\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool, global_max_pool\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from tqdm import tnrange\n",
    "from collections import Counter\n",
    "from ogb.utils import smiles2graph\n",
    "from IPython.display import display, HTML\n",
    "from standardiser import break_bonds, neutralise, unsalt, standardise\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de241df6-74e0-4589-91dd-976459d13c41",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 1: Check system availability </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6687ff3-a763-444f-994d-0b07339d2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_availability():\n",
    "    if \"CUDA_VISIBLE_DEVICES\" not in os.environ:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpu_info = os.popen('nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits').readlines()\n",
    "        gpu_available = 100 - int(gpu_info[0].strip())\n",
    "        gpu_result = f\"\\033[1m\\033[34mGPU availability: \\033[91m{gpu_available:.2f}%\\033[0m\"\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        gpu_result = 'GPU is not available, using CPU instead'\n",
    "\n",
    "    cpu_percentage = psutil.cpu_percent()\n",
    "    cpu_available = 100 - cpu_percentage\n",
    "    cpu_result = f\"\\033[1m\\033[34mCPU availability: \\033[91m{cpu_available:.2f}%\\033[0m\"\n",
    "    \n",
    "    print(gpu_result)\n",
    "    print(cpu_result)\n",
    "    return device\n",
    "\n",
    "device = check_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbae936-f0dd-48b0-ac18-0dd28bfd82f4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 2: Load data </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2680d8-a6ca-416c-bf2c-367a99135e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/leash_bio_brd4.csv')\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d5839-2eb3-4624-ab2f-71130a40ef52",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 3: Remove salts and standardise smiles </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d39e8e-0031-4bf1-a834-372ac79332e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_salts(df):\n",
    "    def remove_salt(smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return ''\n",
    "        \n",
    "        mol = break_bonds.run(mol)\n",
    "        mol = neutralise.run(mol)\n",
    "        non_salt_frags = []\n",
    "        for frag in Chem.GetMolFrags(mol, asMols=True):        \n",
    "            if unsalt.is_nonorganic(frag): \n",
    "                continue \n",
    "            if unsalt.is_salt(frag): \n",
    "                continue      \n",
    "            non_salt_frags.append(frag)\n",
    "        \n",
    "        non_salt_smiles = [Chem.MolToSmiles(frag) for frag in non_salt_frags]\n",
    "        non_salt_smiles = '.'.join(non_salt_smiles) \n",
    "\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(non_salt_smiles)\n",
    "            standard_mol = standardise.run(mol)\n",
    "            standard_smiles = Chem.MolToSmiles(standard_mol)\n",
    "            return standard_smiles\n",
    "        except standardise.StandardiseException as e:\n",
    "            return None\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    df['SMILES_unsalt'] = df['SMILES'].apply(remove_salt)\n",
    "    df_unsalt = df.dropna(subset=['SMILES_unsalt'])\n",
    "    df_unsalt = df_unsalt.drop(columns=['SMILES'])\n",
    "    df_unsalt = df_unsalt.rename(columns={'SMILES_unsalt': 'SMILES'})\n",
    "    final_count = len(df_unsalt)\n",
    "    print(f\"\\033[1m\\033[34mNumber of datapoints removed: \\033[91m{initial_count - final_count}\\033[0m\")\n",
    "    print(f\"\\033[1m\\033[34mNumber of datapoints remaining: \\033[91m{final_count}\\033[0m\")\n",
    "    return df_unsalt, initial_count, final_count\n",
    "\n",
    "df_remove_salts, initial_count, after_salts_count = remove_salts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dc0ef-73f4-46f1-895b-808a5bd8c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_remove_salts.copy()\n",
    "df = df[['id', 'SMILES', 'Target']]\n",
    "\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad8a0e-0447-48fb-a31e-3126b5b83754",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 4: Balance dataset </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc5cb8-c9f0-405e-8a53-629f69e4eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac829b-c096-428a-9f6a-2e91cd5e009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = df[df['Target'] == 0]\n",
    "df_minority = df[df['Target'] == 1]\n",
    "\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=df_minority.shape[0], random_state=42)\n",
    "df = pd.concat([df_majority_downsampled, df_minority])\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ce723-8afe-483a-a165-a6d277c6da56",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 5: Train-Test split </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4198124-3d97-469f-a8cf-541b899a6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['Target'])\n",
    "\n",
    "print(\"Train Data\")\n",
    "display(train_df.head())\n",
    "print(train_df.shape)\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"Test Data\")\n",
    "display(test_df.head())\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6c43a-aacb-4ee0-b53f-5a53e1cda2e1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 6: Visualise train-test data </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02ee91-3191-48a1-a0f8-e098fdc896f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecfp(smiles_list, radius=2, n_bits=2048):\n",
    "    ecfp_list = []\n",
    "    generator = GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            ecfp = generator.GetFingerprint(mol)\n",
    "            ecfp_list.append(np.array(ecfp))\n",
    "        else:\n",
    "            ecfp_list.append(np.zeros(n_bits))\n",
    "    return np.array(ecfp_list)\n",
    "\n",
    "X_train = generate_ecfp(train_df['SMILES'])\n",
    "X_test = generate_ecfp(test_df['SMILES'])\n",
    "y_train = train_df['Target']\n",
    "y_test = test_df['Target']\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(np.vstack((X_train, X_test)))\n",
    "tsne_train = tsne_results[:len(X_train)]\n",
    "tsne_test = tsne_results[len(X_train):]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(tsne_train[:, 0], tsne_train[:, 1], c='#7b1fa2', label=f'Train Data (n={len(X_train)})', s=10, alpha=0.7)\n",
    "plt.scatter(tsne_test[:, 0], tsne_test[:, 1], c='#ff6f00', label=f'Test Data (n={len(X_test)})', s=10, alpha=1)\n",
    "plt.title('t-SNE plot of Train and Test Data')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend()\n",
    "os.makedirs('model_files', exist_ok=True)\n",
    "plt.savefig('model_files/tsne_train_vs_test_data.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa235f53-2e97-4f24-880d-020fb4bd41fa",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 7: Convert Data into Graph format </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1eb6cb-86c5-441f-b3de-9541c7e3eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMoleculeNetDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(CustomMoleculeNetDataset, self).__init__(\".\", transform=None, pre_transform=None)\n",
    "        self.data_list = data_list\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_data_list(df):\n",
    "        data_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            graph = smiles2graph(row['SMILES'])\n",
    "            data = Data(\n",
    "                x=torch.tensor(graph['node_feat']),\n",
    "                edge_index=torch.tensor(graph['edge_index']),\n",
    "                edge_attr=torch.tensor(graph['edge_feat'])\n",
    "            )\n",
    "            data.smiles = row['SMILES']\n",
    "            data.y = torch.tensor([[row['Target']]], dtype=torch.float) \n",
    "            data_list.append(data)\n",
    "        return data_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if isinstance(idx, slice):\n",
    "            return self.data_list[idx.start:idx.stop:idx.step]\n",
    "        elif isinstance(idx, int):\n",
    "            return self.data_list[idx]\n",
    "\n",
    "data_list = CustomMoleculeNetDataset.create_data_list(train_df)\n",
    "dataset = CustomMoleculeNetDataset(data_list)\n",
    "\n",
    "print(\"Dataset type: \", type(dataset))\n",
    "print(\"Dataset features: \", dataset.num_features)\n",
    "print(\"Dataset length: \", len(dataset))\n",
    "print(\"Dataset sample: \", dataset[0])\n",
    "print(\"Sample nodes: \", dataset[0].num_nodes)\n",
    "print(\"Sample edges: \", dataset[0].num_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01795498-9743-42ed-b57b-80dbb8a807d5",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 8: Model Architecture </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b629ec0-6df3-44ee-ac41-3656859f8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class MolecularGraphNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularGraphNeuralNetwork, self).__init__()\n",
    "        embedding_size = 128  \n",
    "        self.initial_conv = GCNConv(dataset.num_features, embedding_size)\n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
    "        self.out = torch.nn.Linear(embedding_size * 2, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(embedding_size)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        x = self.initial_conv(x, edge_index)\n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.bn3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.leaky_relu(x, negative_slope=0.01)\n",
    "        x = torch.cat([global_max_pool(x, batch_index), global_mean_pool(x, batch_index)], dim=1)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "model = MolecularGraphNeuralNetwork().to(device)\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13c46a-f247-4dcd-ae48-690238614dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEarlyStopping:\n",
    "    def __init__(self, patience, min_epochs):\n",
    "        self.patience = patience\n",
    "        self.min_epochs = min_epochs\n",
    "        self.best_loss = np.inf\n",
    "        self.best_epoch = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, epoch, avg_test_loss):\n",
    "        if epoch < self.min_epochs:\n",
    "            return False\n",
    "\n",
    "        if avg_test_loss < self.best_loss:\n",
    "            self.best_loss = avg_test_loss\n",
    "            self.best_epoch = epoch\n",
    "        elif epoch - self.best_epoch >= self.patience:\n",
    "            self.early_stop = True\n",
    "            display(HTML(f\"<font color='green'><small>Early stopping at epoch {epoch+1}</small></font>\"))\n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43f16e-8f5c-4cad-a510-a6a73b211983",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 9: Model Training </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124c189-9feb-4c42-8b12-737b9a2de8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "num_graphs_per_batch = 256\n",
    "n_epochs = 250\n",
    "\n",
    "train_loss_per_fold = {}\n",
    "validation_loss_per_fold = {}\n",
    "skf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, validation_idx) in enumerate(skf.split(dataset.data_list)):\n",
    "    start_time_fold = time.time()\n",
    "    \n",
    "    model = MolecularGraphNeuralNetwork().to(device)\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=20, factor=0.5, min_lr=1e-6)  \n",
    "    custom_early_stopping = CustomEarlyStopping(patience=20, min_epochs=150)\n",
    "\n",
    "    train_loader = DataLoader([dataset.data_list[idx] for idx in train_idx], batch_size=num_graphs_per_batch, shuffle=True, num_workers=3)\n",
    "    validation_loader = DataLoader([dataset.data_list[idx] for idx in validation_idx], batch_size=num_graphs_per_batch, shuffle=True, num_workers=3)\n",
    "    display(HTML(f\"<small>Fold {fold + 1}, Train Data: {len(train_loader.dataset)}, Validation Data: {len(validation_loader.dataset)}</small></font>\"))\n",
    "\n",
    "    train_loss_per_fold[fold] = []\n",
    "    validation_loss_per_fold[fold] = []\n",
    "\n",
    "    for epoch in tnrange(n_epochs, leave=False):\n",
    "        model.train()\n",
    "        epoch_train_losses = []\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "            loss = loss_fn(pred, batch.y.float().to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        epoch_validation_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in validation_loader:\n",
    "                batch = batch.to(device)\n",
    "                pred = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "                loss = loss_fn(pred, batch.y.float().to(device))\n",
    "                epoch_validation_losses.append(loss.item())\n",
    "\n",
    "        train_loss = np.mean(epoch_train_losses)\n",
    "        validation_loss = np.mean(epoch_validation_losses)\n",
    "        train_loss_per_fold[fold].append(train_loss)\n",
    "        validation_loss_per_fold[fold].append(validation_loss)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "        if epoch % 20 == 0:\n",
    "            display(HTML(f\"<font color='grey'><small>Epoch {epoch+1},   TrainLoss {train_loss:.4f},   ValidationLoss {validation_loss:.4f},   LearningRate {current_lr:.6f}</small></font>\"))\n",
    "\n",
    "        if custom_early_stopping(epoch, validation_loss):\n",
    "            break\n",
    "\n",
    "        scheduler.step(validation_loss)\n",
    "        state_dict = model.state_dict()\n",
    "        os.makedirs('model_files', exist_ok=True)\n",
    "        torch.save(state_dict, f'model_files/model_fold_{fold+1}.pth')\n",
    "\n",
    "    np.save(f'model_files/train_losses_fold_{fold+1}.npy', np.array(train_loss_per_fold[fold]))\n",
    "    np.save(f'model_files/validation_losses_fold_{fold+1}.npy', np.array(validation_loss_per_fold[fold]))\n",
    "\n",
    "    end_time_fold = time.time()\n",
    "    fold_time = round((end_time_fold - start_time_fold) / 60, 2)\n",
    "    display(HTML(f\"<font color='green'><b><small>Fold {fold + 1} checkpoints saved in model_fold_{fold+1}.pth, Time Taken: {fold_time:.2f} minutes</small><b></font>\"))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa39bf4-18a3-4e5d-87d8-1a7da91a17c1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 10: Training and Validation losses </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af90ddf-ef41-455d-b21e-563963baf93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_validation_losses(train_loss_per_fold, validation_loss_per_fold, num_folds, save_path=None):\n",
    "    fig, axes = plt.subplots(num_folds, 1, figsize=(9, 3 * num_folds), sharex=True)\n",
    "    for k in range(num_folds):\n",
    "        axes[k].plot(train_loss_per_fold[k], label='Training Loss', color='#e64a19')\n",
    "        axes[k].plot(validation_loss_per_fold[k], label='Validation Loss', color='#388e3c')\n",
    "        axes[k].set_ylabel(f'Losses (Fold {k+1})', fontsize=8)\n",
    "        axes[k].legend(fontsize=8, loc='upper right')\n",
    "        axes[k].set_xlabel('Epoch Number', fontsize=8)\n",
    "        axes[k].tick_params(axis='x', labelsize=8)\n",
    "        axes[k].tick_params(axis='y', labelsize=8)\n",
    "        axes[k].legend(fontsize=8, loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "train_loss_per_fold = {}\n",
    "validation_loss_per_fold = {}\n",
    "\n",
    "for fold in range(NUM_FOLDS):\n",
    "    train_losses = np.load(f'model_files/train_losses_fold_{fold+1}.npy', allow_pickle=True)\n",
    "    validation_losses = np.load(f'model_files/validation_losses_fold_{fold+1}.npy', allow_pickle=True)\n",
    "    train_loss_per_fold[fold] = train_losses.tolist()\n",
    "    validation_loss_per_fold[fold] = validation_losses.tolist()\n",
    "\n",
    "plot_training_validation_losses(train_loss_per_fold, validation_loss_per_fold, NUM_FOLDS, 'model_files/training_and_validation_losses.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ccf00-521b-412b-bd07-6a21471ace83",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 11: Make predictions on test data </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1600025-82e4-4f2e-a8de-afd6f65379b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "num_graphs_per_batch = 256\n",
    "model_folder = 'model_files'\n",
    "\n",
    "class CustomMoleculeNetDataset_predict(InMemoryDataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(CustomMoleculeNetDataset, self).__init__(\".\", transform=None, pre_transform=None)\n",
    "        self.data_list = data_list\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_data_list(df):\n",
    "        data_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            graph = smiles2graph(row['SMILES'])\n",
    "            data = Data(\n",
    "                x=torch.tensor(graph['node_feat']),\n",
    "                edge_index=torch.tensor(graph['edge_index']),\n",
    "                edge_attr=torch.tensor(graph['edge_feat'])\n",
    "            )\n",
    "            data.smiles = row['SMILES']\n",
    "            data_list.append(data)\n",
    "        return data_list\n",
    "\n",
    "test_data = CustomMoleculeNetDataset_predict.create_data_list(test_df)\n",
    "test_loader = DataLoader(test_data, batch_size=num_graphs_per_batch)\n",
    "\n",
    "models = []\n",
    "for fold in range(NUM_FOLDS):\n",
    "    model = MolecularGraphNeuralNetwork()\n",
    "    model_checkpoint_path = f'{model_folder}/model_fold_{fold+1}.pth'\n",
    "    checkpoint = torch.load(model_checkpoint_path, map_location=torch.device('cpu')) \n",
    "\n",
    "    if 'module.' in list(checkpoint.keys())[0]:\n",
    "        checkpoint = {k.replace('module.', ''): v for k, v in checkpoint.items()}\n",
    "\n",
    "    model.load_state_dict(checkpoint)  \n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "    \n",
    "predictions = []\n",
    "for batch in test_loader:\n",
    "    batch = batch.to(device)\n",
    "    batch_predictions = []\n",
    "    for model in models:\n",
    "        model = model.to(device)  \n",
    "        with torch.no_grad():\n",
    "            pred = model(batch.x.float().to(device), batch.edge_index.to(device), batch.batch.to(device))\n",
    "            batch_predictions.append(torch.sigmoid(pred).cpu().numpy())\n",
    "\n",
    "    batch_predictions = np.concatenate(batch_predictions, axis=1)\n",
    "    mean_predictions = batch_predictions.mean(axis=1)\n",
    "    mean_predictions = (mean_predictions > 0.5).astype(int)\n",
    "    predictions.extend(mean_predictions)\n",
    "\n",
    "test_results = pd.DataFrame({'id':test_df['id'], 'SMILES': test_df['SMILES'], 'Target': test_df['Target'], 'Target_pred': predictions})\n",
    "display(test_results.head())\n",
    "print(test_results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3f72f-0a51-4aa0-afdc-32517f45b917",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4B6587; color:#F0E5CF; padding: 1px; border-radius: 10px;\">\n",
    "    <h2 style=\"font-size: 16px; margin-left: 10px;\"> Step 12: Model Evaluation </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7cd06-ab29-4a8d-ae8a-796e131e1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from my_cm import *\n",
    "\n",
    "true_labels = test_results['Target']\n",
    "predicted_labels = test_results['Target_pred']\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "PrettyConfusionMatrix(cm, labels=('0', '1'), save_path='model_files/my_confusion_matrix.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
